<!DOCTYPE HTML>
<html lang="en">

<head>
    <meta http-equiv="Content-Type" content="text/html; charset=UTF-8">

    <title>Abdullah Al Noman</title>

    <meta name="author" content="Abdullah Al Noman">
    <meta name="viewport" content="width=device-width, initial-scale=1">

    <link rel="stylesheet" href="styles.css">
    <link rel="icon" type="image/png" href="assets/demo-fav-icon.png">
    <link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/6.0.0-beta3/css/all.min.css">
</head>

<style>
body, div, p, a {
    font-family: 'Lato', Verdana, Helvetica, sans-serif;
    font-size: 13px;
    word-spacing: -1px;
    color: #383737;
    letter-spacing: -0.15px;
}
body {
    margin: 0px !important;
}
body.dark-mode {
    background: #0d1117;
    transition: color 0.3s ease;
}
.main-div {
    width: 100%;
    max-width: 800px;
    border: 0px;
    border-spacing: 0px;
    border-collapse: separate;
    margin-right: auto;
    margin-left: auto;
    box-shadow: 0 0 1px 1.5px #ddd;
    border-left: 1.5px solid #eee;
    border-right: 1.5px solid #eee;
}
body.dark-mode .main-div {
    border: 1.5px solid #0a151a;
    box-shadow: 0 0 1px 1.5px #040d11;
    background: #091b23;
}
.sub-div {
    padding: 20px 20px 10px;
    border-top: 2px solid #eee;
}
body.dark-mode .sub-div {
    border-top: 2px solid #0a151a;
}
body.dark-mode .publication-section-div {
    border: 1.5px solid #0a151a;
}
img {
    border: 1px solid #eee;
    padding: 7px;
    width: 200px;
    height: 150px;
    background-size: cover;
}
.publication-section-div {
    display: flex; 
    flex-direction: row; 
    padding: 10px;
    gap: 15px;
    border: 1.5px solid #eee;
    margin: 12px 20px;
}
.my-links-div {
    padding: 20px;
    border-top: 2px solid #eee;
    display: flex;
    gap: 10px;
}
body.dark-mode .my-links-div {
    border-top: 2px solid #0a151a;
}
a.my-link {
    border: 1.5px solid #ddd;
    padding: 5px 10px 7px;
    border-radius: 100px;
    background: #e8f2f6;
}
body.dark-mode a.my-link {
    border: 1.5px solid #091f1e;
    padding: 5px 10px 7px;
    border-radius: 100px;
    background: #09231f;
    box-shadow: 0 0 1px 1px #061413;
}
a {
    color:#1772d0; 
    text-decoration:none;
}
body.dark-mode a {
    color: #beaa23!important;
}
p {
    font-size: 13px;
    font-family: 'Lato', Verdana, Helvetica, sans-serif;
    line-height: 20px;
}
body.dark-mode p {
    color: #ddd;
}
footer {
    background-color: #333;
    color: #fff;
    text-align: center;
    padding: 1rem 0;
    margin-top: 2rem;
}
footer p {
    margin: 0;
}
name {
    font-family: 'Lato', Verdana, Helvetica, sans-serif;
    font-size: 32px;
}


.dark-mode-div {
    display: flex;
    flex-direction: row-reverse;
}
button#darkModeToggle {
    position: fixed;
    width: 35px;
    height: 35px;
    font-size: 20px;
    border-radius: 100%;
    border: 2px solid #ddd;
    margin: 10px;
    color: #333;
    transition: color 0.3s ease;
    display: flex;
    align-items: center;
    justify-content: center;
}
body.dark-mode button#darkModeToggle {
    background: #1a1a1a;
    color: #fff;
    border: 1.5px solid #181818;
    box-shadow: 0 0 1px 1px #0c0c0c;
}
body.dark-mode #darkModeToggle {
    color: #fff; /* Dark mode color */
}
</style>

<body>
<div class="main-div">
<div class="dark-mode-div">
    <button id="darkModeToggle">
        <i id="darkModeIcon" class="fas fa-moon"></i>
    </button>
</div>
<script>
// Get the toggle button and icon elements
const toggleButton = document.getElementById('darkModeToggle');
const darkModeIcon = document.getElementById('darkModeIcon');

// Check the saved dark mode preference in localStorage
const isDarkMode = localStorage.getItem('dark-mode') === 'true';

// Apply the saved dark mode preference
if (isDarkMode) {
    document.body.classList.add('dark-mode');
    darkModeIcon.classList.remove('fa-moon');
    darkModeIcon.classList.add('fa-sun');
}

// Event listener for the toggle button
toggleButton.addEventListener('click', () => {
    // Toggle dark mode
    document.body.classList.toggle('dark-mode');
    
    // Update the icon based on the dark mode status
    if (document.body.classList.contains('dark-mode')) {
        darkModeIcon.classList.remove('fa-moon');
        darkModeIcon.classList.add('fa-sun');
        localStorage.setItem('dark-mode', 'true'); // Save dark mode preference
    } else {
        darkModeIcon.classList.remove('fa-sun');
        darkModeIcon.classList.add('fa-moon');
        localStorage.setItem('dark-mode', 'false'); // Save light mode preference
    }
});
</script>
	<div style="width:100%; margin-right:auto; margin-left:auto;">
	    <div style="display:flex; flex-direction:row; align-items:center; padding:2.5%; box-sizing:border-box;">
		<div style="flex: 1; padding:10px; max-width:65%;">
		    <p style="text-align:center; font-size:32px; font-family: 'Lato', Verdana, Helvetica, sans-serif;">
			<name>Abdullah Al Noman</name>
		    </p>
		    <p>
			I am a Ph.D. student in the EECS department at MIT, advised by Professor 
			<a style="color:#1772d0; text-decoration:none;" href="https://meche.mit.edu/people/faculty/ALBERTOR@MIT.EDU">Alberto Rodriguez</a>
			and Professor <a style="color:#1772d0; text-decoration:none;" href="http://people.csail.mit.edu/pulkitag/">Pulkit Agrawal</a>. I'm interested in robot manipulation and physical interaction.
			
			I am fortunate to be supported by the <a style="color:#1772d0; text-decoration:none;" href="https://www.nsfgrfp.org/">NSF GRFP</a>. 
		    </p>
		    <p>
			I received my S.M. in EECS from MIT and my B.S. in Mechanical Engineering from UC San Diego, where I
			worked with Professor <a style="color:#1772d0; text-decoration:none;" href="https://yip.eng.ucsd.edu/">Michael Yip</a>. I have also spent time as a research intern at 
			<a style="color:#1772d0; text-decoration:none;" href="https://la.disneyresearch.com/">Disney Research Los Angeles</a> and 
			<a style="color:#1772d0; text-decoration:none;" href="https://research.nvidia.com/labs/srl/">NVIDIA's Seattle Robotics Lab</a>.
		    </p>
		</div>
		<div style="flex: 0 0 auto; padding:10px; max-width:35%;">
		    <img style="width:100%; height:100%; border-radius:50%; box-shadow:0 0 0.5px 0.8px #ccc; border:1px solid #ddd; padding:5px;" alt="profile photo" src="assets/demo-profile-pic.png">
		</div>
	    </div>
	    <div class="my-links-div">
		<a class="my-link" style="color:#1772d0; text-decoration:none;" href="mailto:asimeono@mit.edu">Email</a>
		<a class="my-link" style="color:#1772d0; text-decoration:none;" href="https://scholar.google.com/citations?user=RNDrSGYAAAAJ&hl=en" target="_blank">Google Scholar</a>
		<a class="my-link" style="color:#1772d0; text-decoration:none;" href="https://www.linkedin.com/in/anthonysimeonov/" target="_blank">LinkedIn</a>
	    </div>

	    <div class="sub-div">
		<h2 style="margin: 0px;">Research</h2>
		<p style="font-size:14px; font-family:'Lato', Verdana, Helvetica, sans-serif;">
		    I'm currently interested in machine learning for perception-driven planning and control, applied to problems in robot manipulation and physical interaction.
		    The goal is to equip robots with <em>reusable</em> manipulation skills, through a combination of effective perceptual representations and reactive behaviors. 
		    Previously, I have studied the design, modeling, and control of inherently compliant artificial muscle actuators.
		</p>
	    </div>
	
	    <div class="sub-div">
		<h2 style="margin: 0px;">Publications</h2>
	    </div>
	</div>

	<div style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;">
	    <div class="publication-section-div">
		<div class="publications-section-1">
		    <img src='assets/place_seq3.gif' width="100%" />
		</div>
		<div class="publications-section-2">
		    <a style="color:#1772d0; text-decoration:none;" href="https://arxiv.org/abs/2407.16677">
			<papertitle>From Imitation to Refinement - Residual RL for Precise Visual Assembly</papertitle>
		    </a>
		    <br>
		    <a style="color:#1772d0; text-decoration:none;" href="https://ankile.com/"> Lars Ankile</a>,
		    <strong>Anthony Simeonov</strong>,
		    <a style="color:#1772d0; text-decoration:none;" href="https://idanshen.github.io/"> Idan Shenfeld</a>,
		    <a style="color:#1772d0; text-decoration:none;" href="https://marceltorne.github.io/"> Marcel Torne</a>,
		    <a style="color:#1772d0; text-decoration:none;" href="http://people.csail.mit.edu/pulkitag/"> Pulkit Agrawal</a>
		    <br>
		    <em>arXiv</em>, 2024
		    <br>
		    <a style="color:#1772d0; text-decoration:none;" href="https://residual-assembly.github.io/">project page</a>
		    <br>
		    <p>A BC + RL pipeline for precise manipulation tasks like assembly. Fine-tuning BC-trained policies with action chunking and diffusion de-noising requires specialized RL methods. We simplify such RL fine-tuning with simple residual policies trained with PPO.</p>
		</div>
	    </div>
	
	    <div class="publication-section-div">
		<div class="publications-section-1">
		    <img src='assets/mug_real_sim_rialto_fast.gif' width="100%" />
		</div>
		<div class="publications-section-2">
		    <a style="color:#1772d0; text-decoration:none;" href="https://arxiv.org/abs/2403.03949">
			<papertitle>Reconciling Reality through Simulation: A Real-to-Sim-to-Real Approach for Robust Manipulation</papertitle>
		    </a>
		    <br>
		    <a style="color:#1772d0; text-decoration:none;" href="https://marceltorne.github.io/"> Marcel Torne</a>,
		    <strong>Anthony Simeonov</strong>,
		    <a style="color:#1772d0; text-decoration:none;" href="https://supersglzc.github.io/"> Zechu Li</a>,
		    <a style="color:#1772d0; text-decoration:none;" href="https://real-to-sim-to-real.github.io/RialTo/"> April Chan</a>,
		    <a style="color:#1772d0; text-decoration:none;" href="https://taochenshh.github.io/"> Tao Chen</a>,
		    <a style="color:#1772d0; text-decoration:none;" href="https://homes.cs.washington.edu/~abhgupta/"> Abhishek Gupta*</a>,
		    <a style="color:#1772d0; text-decoration:none;" href="http://people.csail.mit.edu/pulkitag/"> Pulkit Agrawal*</a>(*equal advising)
		    <br>
		    <em>RSS</em>, 2024
		    <br>
		    <a style="color:#1772d0; text-decoration:none;" href="https://real-to-sim-to-real.github.io/RialTo/">project page</a>
		    <br>
		    <p>Learning robust manipulation policies by combining real-world imitation learning and reinforcement learning in simulation. RL in sim uses digital twin assets that reflect the geometry, appearance, and kinematics of the target deployment scene.</p>
		</div>
	    </div>
	
	    <div class="publication-section-div">
		<div class="publications-section-1">
		    <img src='assets/juicer_quick_s2.gif' width="100%" />
		</div>
		<div class="publications-section-2">
		    <a href="https://arxiv.org/abs/2404.03729">
			<papertitle>JUICER: Data-Efficient Imitation Learning for Robotic Assembly</papertitle>
		    </a>
		    <br>
		    <a style="color:#1772d0; text-decoration:none;" href="https://ankile.com/"> Lars Ankile</a>,
		    <strong>Anthony Simeonov</strong>,
		    <a style="color:#1772d0; text-decoration:none;" href="https://idanshen.github.io/"> Idan Shenfeld</a>,
		    <a style="color:#1772d0; text-decoration:none;" href="http://people.csail.mit.edu/pulkitag/"> Pulkit Agrawal</a>
		    <br>
		    <em>IROS</em>, 2024
		    <br>
		    <a style="color:#1772d0; text-decoration:none;" href="https://imitation-juicer.github.io/">project page</a>
		    <br>
		    <p>A pipeline for learning image-based policies for precise, long-horizon assembly tasks from a small number of demonstrations by combining expressive policy architectures and various techniques for dataset expansion.</p>
		</div>
	    </div>
	
	    <div class="publication-section-div">
		<div class="publications-section-1">
		    <img src='assets/halp_pour.gif' width="100%" />
		</div>
		<div class="publications-section-2">
		    <a style="color:#1772d0; text-decoration:none;" href="https://arxiv.org/abs/2309.14321">
			<papertitle>Lifelong Robot Learning with Human Assisted Language Planners</papertitle>
		    </a>
		    <br>
		    <a style="color:#1772d0; text-decoration:none;" href="https://sites.google.com/mit.edu/halp-robot-learning"> Meenal Parakh*</a>,
		    <a style="color:#1772d0; text-decoration:none;" href="https://sites.google.com/mit.edu/halp-robot-learning"> Alisha Fong*</a>,
		    <strong>Anthony Simeonov</strong>,
		    <a style="color:#1772d0; text-decoration:none;" href="https://taochenshh.github.io/"> Tao Chen</a>,
		    <a style="color:#1772d0; text-decoration:none;" href="https://homes.cs.washington.edu/~abhgupta/"> Abhishek Gupta</a>,
		    <a style="color:#1772d0; text-decoration:none;" href="http://people.csail.mit.edu/pulkitag/"> Pulkit Agrawal</a>(*equal contribution)
		    <br>
		    <em>ICRA</em>, 2024
		    <br>
		    <a style="color:#1772d0; text-decoration:none;" href="https://sites.google.com/mit.edu/halp-robot-learning">project page</a>
		    <br>
		    <p>An LLM-based task planner that can learn new skills opens doors for continual learning.</p>
		</div>
	    </div>
	
	    <div class="publication-section-div">
		<div class="publications-section-1">
		    <img src='assets/rpdiff-real-sim-spedup-notext-notitlec.gif' width="100%" />
		</div>
		<div class="publications-section-2">
		    <a style="color:#1772d0; text-decoration:none;" href="https://arxiv.org/abs/2307.04751">
			<papertitle>Shelving, Stacking, Hanging: Relational Pose Diffusion for Multi-modal Rearrangement</papertitle>
		    </a>
		    <br>
		    <strong>Anthony Simeonov</strong>,
		    <a style="color:#1772d0; text-decoration:none;" href="https://imankgoyal.github.io/"> Ankit Goyal*</a>,
		    <a style="color:#1772d0; text-decoration:none;" href="http://lucasmanuelli.com/"> Lucas Manuelli*</a>,
		    <a style="color:#1772d0; text-decoration:none;" href="https://yenchenlin.me/"> Lin Yen-Chen</a>,
		    <a style="color:#1772d0; text-decoration:none;" href="https://www.linkedin.com/in/alina-sarmiento/"> Alina Sarmiento</a>,
		    <a style="color:#1772d0; text-decoration:none;" href="https://meche.mit.edu/people/faculty/ALBERTOR@MIT.EDU"> Alberto Rodriguez</a>,
		    <a style="color:#1772d0; text-decoration:none;" href="http://people.csail.mit.edu/pulkitag/"> Pulkit Agrawal**</a>,
		    <a style="color:#1772d0; text-decoration:none;" href="https://homes.cs.washington.edu/~fox/"> Dieter Fox**</a>(*equal contribution, **equal advising)
		    <br>
		    <em>CoRL</em>, 2023
		    <br>
		    <a style="color:#1772d0; text-decoration:none;" href="https://anthonysimeonov.github.io/rpdiff-multi-modal/">project page</a> / <a href="https://github.com/anthonysimeonov/rpdiff">code</a>
		    <br>
		    <p>Performing 6-DoF relational rearrangement between objects and scenes. Iterative pose de-noising via diffusion helps handle multi-modality and local scene cropping improves generalization.</p>
		</div>
	    </div>
	
	    <div class="publication-section-div">
		<div class="publications-section-1">
		    <img src='assets/lndf.gif' width="100%" />
		</div>
		<div class="publications-section-2">
		    <a style="color:#1772d0; text-decoration:none;" href="https://arxiv.org/abs/2302.03573">
			<papertitle>Local Neural Descriptor Fields: Locally Conditioned Object Representations for Manipulation</papertitle>
		    </a>
		    <br>
		    <a style="color:#1772d0; text-decoration:none;" href="https://elchun.github.io/">Ethan Chun</a>,
		    <a style="color:#1772d0; text-decoration:none;" href="https://yilundu.github.io/">Yilun Du</a>,
		    <strong>Anthony Simeonov</strong>,
		    <a style="color:#1772d0; text-decoration:none;" href="https://people.csail.mit.edu/tlp/">Tomás Lozano-Pérez</a>,
		    <a style="color:#1772d0; text-decoration:none;" href="https://people.csail.mit.edu/lpk/">Leslie Kaelbling</a>
		    <br>
		    <em>ICRA</em>, 2023 
		    <br>
		    <a style="color:#1772d0; text-decoration:none;" href="https://elchun.github.io/lndf/">project page</a> / <a href="https://github.com/elchun/lndf_robot">code</a>
		    <br>
		    <p>Local point cloud encoders help 3D neural descriptor fields generalize to more diverse global shapes and improve robustness to occlusions</p>
		</div>
	    </div>
	    
	    <div class="publication-section-div">
		<div class="publications-section-1">
		    <img src='assets/rndf_bowl_bottle_notext.gif' width="100%" />
		</div>
		<div class="publications-section-2">
		    <a style="color:#1772d0; text-decoration:none;" href="https://arxiv.org/abs/2211.09786">
			<papertitle>SE(3)-Equivariant Relational Rearrangement with Neural Descriptor Fields</papertitle>
		    </a>
		    <br>
		    <strong>Anthony Simeonov*</strong>,
		    <a style="color:#1772d0; text-decoration:none;" href="https://yilundu.github.io/">Yilun Du*</a>,
		    <a style="color:#1772d0; text-decoration:none;" href="https://yenchenlin.me/">Lin Yen-Chen</a>,
		    <a style="color:#1772d0; text-decoration:none;" href="http://meche.mit.edu/people/faculty/ALBERTOR@MIT.EDU">Alberto Rodriguez</a>,
		    <a href="https://people.csail.mit.edu/lpk/">Leslie P. Kaelbling</a>,
		    <a href="https://people.csail.mit.edu/tlp/">Tomás Lozano-Pérez</a>,
		    <a href="http://people.csail.mit.edu/pulkitag/">Pulkit Agrawal</a> (*equal contribution)
		    <br>
		    <em>CoRL</em>, 2022 
		    <br>
		    <a href="https://anthonysimeonov.github.io/r-ndf/">project page</a> / <a href="https://github.com/anthonysimeonov/relational_ndf">code</a>
		    <br>
		    <p>Applying 3D neural descriptor fields in a pairwise fashion, to enable relational rearrangement with pairs of unseen objects in arbitrary poses.</p>
		</div>
	    </div>
	    
	    <div class="publication-section-div">
		<div class="publications-section-1">
		    <img src='assets/mira-teaser.png' width="100%" />
		</div>
		<div class="publications-section-2">
		    <a href="https://arxiv.org/abs/2212.06088">
			<papertitle>MIRA: Mental Imagery for Robotic Affordances</papertitle>
		    </a>
		    <br>
		    <a href="https://yenchenlin.me/">Lin Yen-Chen</a>,
		    <a href="https://www.peteflorence.com/">Pete Florence</a>,
		    <a href="https://andyzeng.github.io/">Andy Zeng</a>,
		    <a href="https://jonbarron.info/">Johnathon T. Barron</a>,
		    <a href="https://yilundu.github.io/">Yilun Du</a>,
		    <a href="https://people.csail.mit.edu/weichium/">Wei-Chiu Ma</a>,
		    <strong>Anthony Simeonov</strong>,
		    <a href="http://meche.mit.edu/people/faculty/ALBERTOR@MIT.EDU">Alberto Rodriguez</a>,
		    <a href="http://web.mit.edu/phillipi/">Phillip Isola</a>
		    <br>
		    <em>CoRL</em>, 2022 
		    <br>
		    <a href="https://yenchenlin.me/mira/">project page</a>
		    <br>
		    <p>NeRF enables synthesizing orthographic views from virtual camera poses, allowing search for 6-DoF placing actions represented by pixels in the rendered image (positions) and the camera pose used to generate the image (orientations)</p>
		</div>
	    </div>
	    
	    <div class="publication-section-div">
		<div class="publications-section-1">
		    <img src='assets/mug_cut.gif' width="100%" />
		</div>
		<div class="publications-section-2">
		    <a href="https://arxiv.org/abs/2112.05124">
			<papertitle>Neural Descriptor Fields: SE(3)-Equivariant Object Representations for Manipulation</papertitle>
		    </a>
		    <br>
		    <strong>Anthony Simeonov*</strong>,
		    <a href="https://yilundu.github.io/">Yilun Du*</a>,
		    <a href="https://taiya.github.io/">Andrea Tagliasacchi</a>,
		    <a href="http://web.mit.edu/cocosci/josh.html">Joshua Tenenbaum</a>,
		    <a href="http://meche.mit.edu/people/faculty/ALBERTOR@MIT.EDU">Alberto Rodriguez</a>,
		    <a href="http://people.csail.mit.edu/pulkitag/">Pulkit Agrawal**</a>,
		    <a href="https://www.vincentsitzmann.com/">Vincent Sitzmann**</a> (*equal contribution, order determined by coin flip. **equal advising)
		    <br>
		    <em>ICRA</em>, 2022
		    <br>
		    <a href="https://yilundu.github.io/ndf/">project page</a> / <a href="https://github.com/anthonysimeonov/ndf_robot">code</a>
		    <br>
		    <p>A novel representation that models objects as 3D neural fields of descriptors. We apply this representation to enable pick-and-place on unseen objects in out-of-distribution poses from a small handful of demonstrations.</p>
		</div>
	    </div>
	    
	    <div class="publication-section-div">
		<div class="publications-section-1">
		    <img src='assets/multistep_taller.png' width="100%" />
		</div>
		<div class="publications-section-2">
		    <a href="https://arxiv.org/abs/2011.08177">
			<papertitle>A Long Horizon Planning Framework for Manipulating Rigid Pointcloud Objects</papertitle>
		    </a>
		    <br>
		    <strong>Anthony Simeonov</strong>,
		    <a href="https://yilundu.github.io/">Yilun Du</a>,
		    <a href="http://people.csail.mit.edu/beomjoon/">Beomjoon Kim</a>,
		    <a href="https://www.linkedin.com/in/francois-hogan-2b4025b6/">Francois Hogan</a>,
		    <a href="http://web.mit.edu/cocosci/josh.html">Joshua Tenenbaum</a>,
		    <a href="http://people.csail.mit.edu/pulkitag/">Pulkit Agrawal</a>,
		    <a href="http://meche.mit.edu/people/faculty/ALBERTOR@MIT.EDU">Alberto Rodriguez</a>
		    <br>
		    <em>CoRL</em>, 2020
		    <br>
		    <a href="https://anthonysimeonov.github.io/rpo-planning-framework/">project page</a>
		    <br>
		    <p>A framework for solving long-horizon planning problems involving manipulation of rigid objects that operates directly from a point-cloud observation.</p>
		</div>
	    </div>
		
	    <div class="publication-section-div">
		<div class="publications-section-1">
		    <img src='assets/mpnet-planning-quad.png' width="100%"/>
		</div>
		<div class="publications-section-2">
		    <a style="color:#1772d0; text-decoration:none;" href="https://arxiv.org/pdf/1907.06013.pdf" id="MPNet_journal">
			<papertitle>Motion Planning Networks: Bridging the Gap Between Learning-based and Classical Motion Planners</papertitle>
		    </a>
		    <br>
		    <a style="color:#1772d0; text-decoration:none;" href="https://scholar.google.com/citations?user=Lkrx2SkAAAAJ&hl=en">Ahmed Qureshi</a>,
		    Yinglong Miao,
		    <strong>Anthony Simeonov</strong>,
		    <a style="color:#1772d0; text-decoration:none;" href="https://yip.eng.ucsd.edu/">Michael C. Yip</a>
		    <br>
		    <em>TRO</em>, 2020 
		    <br>
		    <a style="color:#1772d0; text-decoration:none;" href="https://sites.google.com/view/mpnet/home">project page</a>
		    <br>
		    <p>By encoding raw observations of obstacle geometry into a latent representation, we can distill the capabilities of an expensive planning algorithm into a neural network, allowing significant speedups in finding near-optimal collision-free paths.</p>
		</div>
	    </div>
	    
	    <div class="publication-section-div">
		<div class="publications-section-1">
		    <img src='assets/baxter_mpnet_quad.png' width="100%" />
		</div>
		<div class="publications-section-2">
		    <a style="color:#1772d0; text-decoration:none;" href="https://arxiv.org/pdf/1806.05767.pdf">
			<papertitle>Motion Planning Networks</papertitle>
		    </a>
		    <br>
		    <a style="color:#1772d0; text-decoration:none;" href="https://scholar.google.com/citations?user=Lkrx2SkAAAAJ&hl=en">Ahmed Qureshi</a>,
		    <strong>Anthony Simeonov</strong>,
		    <a style="color:#1772d0; text-decoration:none;" href="https://scholar.google.com/citations?user=juDRQNkAAAAJ&hl=en">Mayur J. Bency</a>,
		    <a style="color:#1772d0; text-decoration:none;" href="https://yip.eng.ucsd.edu/">Michael C. Yip</a>
		    <br>
		    <em>ICRA</em>, 2019
		    <br>
		    <a style="color:#1772d0; text-decoration:none;" href="https://sites.google.com/view/mpnet/home">project page</a>
		    <br>
		    <p>This paper is subsumed by <a href="#MPNet_journal">our journal paper</a>.</p>
		</div>
	    </div>
	    
	    <div class="publication-section-div">
		<div class="publications-section-1">
		    <img src='assets/bundling-schematic-quad.png' width="100%" />
		</div>
		<div class="publications-section-2">
		    <a style="color:#1772d0; text-decoration:none;" href="https://97315462-8792-4096-8cb2-f015b393fa99.filesusr.com/ugd/e4c3d0_5d09f93d365447fca819af0fc4ad1a9a.pdf">
			<papertitle>Bundled super-coiled polymer artificial muscles: Design, characterization, and modeling</papertitle>
		    </a>
		    <br>
		    <strong>Anthony Simeonov</strong>,
		    <a style="color:#1772d0; text-decoration:none;" href="https://www.linkedin.com/in/taylor-henderson-565204133/">Taylor Henderson</a>,
		    <a style="color:#1772d0; text-decoration:none;" href="https://www.linkedin.com/in/zixuan-lan-498b46ab/">Zixuan Lan</a>,
		    <a style="color:#1772d0; text-decoration:none;" href="https://www.linkedin.com/in/guhansundar/">Guhan Sundar</a>,
		    Adam Factor,
		    <a style="color:#1772d0; text-decoration:none;" href="https://www.unr.edu/me/people/jun-zhang"> Jun Zhang</a>,
		    <a style="color:#1772d0; text-decoration:none;" href="https://yip.eng.ucsd.edu/">Michael C. Yip</a>
		    <br>
		    <em>RA-L</em>, 2018
		    <p>Empirical study of the performance tradeoffs between different bundling techniques for thermally-driven, compliant artificial muscle actuators.</p>
		</div>
	    </div>
	    
	    <div class="publication-section-div">
		<div class="publications-section-1">
		    <img src='assets/stickman-sequence.png' width="100%" />
		</div>
		<div class="publications-section-2">
		    <a style="color:#1772d0; text-decoration:none;" href="https://s3-us-west-1.amazonaws.com/disneyresearch/wp-content/uploads/20180515182735/Stickman-Towards-a-Human-Scale-Acrobatic-Robot-Paper.pdf">
			<papertitle>Stickman: Towards a Human Scale Acrobatic Robot</papertitle>
		    </a>
		    <br>
		    <a style="color:#1772d0; text-decoration:none;" href="https://www.linkedin.com/in/morganthomaspope/">Morgan T. Pope</a>, 
		    Steven Christensen, 
		    <a style="color:#1772d0; text-decoration:none;" href="https://scholar.google.com/citations?user=COZRMZUAAAAJ&hl=en">David Christensen</a>, 
		    <strong>Anthony Simeonov</strong>, 
		    <a style="color:#1772d0; text-decoration:none;" href="https://www.linkedin.com/in/grant-imahara-53411b5/">Grant Imahara</a>, 
		    <a style="color:#1772d0; text-decoration:none;" href="http://www.mce.caltech.edu/people/gunter">Günter Niemeyer</a>
		    <br>
		    <em>ICRA</em>, 2018
		    <p>We present a two DOF robot that is launched from a gravity-driven pendulum and executes a variety of mid-air stunts. The robot uses a combination of onboard sensors to perform state estimation and inform actuator timing.</p>
		    <p>This research is part of the basis of Imagineering's <a href="https://la.disneyresearch.com/stuntronics/">Stuntronics</a> project.</p>
		</div>
	    </div>  
	    
	    <div class="publication-section-div">
		<div class="publications-section-1">
		    <img src='assets/sms-3d-hysteresis-diagram.png' width="100%" />
		</div>
		<div class="publications-section-2">
		    <a style="color:#1772d0; text-decoration:none;" href="https://www.researchgate.net/profile/Jun_Zhang199/publication/322377486_Three-dimensional_Hysteresis_Compensation_Enhances_Accuracy_of_Robotic_Artificial_Muscles/links/5a58e6beaca2727d60815349/Three-dimensional-Hysteresis-Compensation-Enhances-Accuracy-of-Robotic-Artificial-Muscles.pdf">
			<papertitle>Three-dimensional hysteresis compensation enhances accuracy of robotic artificial muscles</papertitle>
		    </a>
		    <br>
		    <a style="color:#1772d0; text-decoration:none;" href="https://www.unr.edu/me/people/jun-zhang"> Jun Zhang</a>, 
		    <strong>Anthony Simeonov</strong>, 
		    <a style="color:#1772d0; text-decoration:none;" href="https://yip.eng.ucsd.edu/">Michael C. Yip</a>
		    <br>
		    <em>Smart Materials and Structures</em>, 2018
		    <p>A new modeling scheme for capturing the coupled hysteresis between tension, strain, and input, which is used for improved control of artificial muscle actuators.</p>
		</div>
	    </div>
		
	    <div class="publication-section-div">
		<div class="publications-section-1">
		    <img src='assets/scp-hysteresis-figs.png' width="100%" />
		</div>
		<div class="publications-section-2">
		    <a style="color:#1772d0; text-decoration:none;" href="https://97315462-8792-4096-8cb2-f015b393fa99.filesusr.com/ugd/e4c3d0_93f47f3fd74944bf97665a5c877bdce4.pdf">
			<papertitle>Modeling and inverse compensation of hysteresis in supercoiled polymer artificial muscles</papertitle>
		    </a>
		    <br>
		    <a style="color:#1772d0; text-decoration:none;" href="https://www.unr.edu/me/people/jun-zhang"> Jun Zhang</a>, 
		    <a style="color:#1772d0; text-decoration:none;" href="https://www.linkedin.com/in/kiyer95/">Kaushik Iyer</a>, 
		    <strong>Anthony Simeonov</strong>, 
		    <a style="color:#1772d0; text-decoration:none;" href="https://yip.eng.ucsd.edu/">Michael C. Yip</a>
		    <br>
		    <em>RA-L</em>, 2017
		    <p>We propose three new models for characterizing the hysteresis present in super-coiled polymer artificial muscles, and demonstrate their use for accurate open-loop control.</p>
		</div>
	    </div>
	</div>
	
	<div class="sub-div">
	    <h2 style="margin: 0px;">Workshop Papers</h2>
	</div>
	<div class="publication-section-div">
	    <div class="publications-section-1">
	    	<img src='assets/multistep_taller.png' width="100%" />
	    </div>
	    <div class="publications-section-2">
	        <a style="color:#1772d0; text-decoration:none;" href="https://rss2020vlrrm.github.io/papers/14_CameraReadySubmission_LearningManipSkills_RSS2020_VLRRM_CameraReady.pdf">
		    <papertitle>Learning to Plan with Pointcloud Affordances for General-Purpose Dexterous Manipulation</papertitle>
	        </a>
	        <br>
	        <strong>Anthony Simeonov</strong>,
	        <a style="color:#1772d0; text-decoration:none;" href="https://yilundu.github.io/">Yilun Du</a>,
	        <a style="color:#1772d0; text-decoration:none;" href="http://people.csail.mit.edu/beomjoon/">Beomjoon Kim</a>,
	    	<a style="color:#1772d0; text-decoration:none;" href="https://www.linkedin.com/in/francois-hogan-2b4025b6/">Francois Hogan</a>,
	    	<a style="color:#1772d0; text-decoration:none;" href="http://people.csail.mit.edu/pulkitag/">Pulkit Agrawal</a>,
	    	<a style="color:#1772d0; text-decoration:none;" href="http://meche.mit.edu/people/faculty/ALBERTOR@MIT.EDU">Alberto Rodriguez</a>
	    	<br>
	    	<em>RSS 2020 Workshops on Visual Learning and Reasoning for Robotic Manipulation, and Learning in Task and Motion Planning</em>
	    </div>
	</div>

	<footer style="background-color: #f8f8f8; color: #333; text-align: center; padding: 1rem 0; margin-top: 2rem;border-top: 2px solid #eee;">
		<p>© 2024 Abdullah Al Noman. All rights reserved.</p>
	</footer>
</div>
</body>
</html>
